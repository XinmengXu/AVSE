<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Attentional Multi-layer Feature Fusion Convolution Network for Audio-visual Speech Enhancement</title>
    <link href="../../css/bootstrap.min.css" rel="stylesheet">
  </head>
  <style type="text/css">
    main {
    padding-bottom: 50px;
    }
    header a:link {
    color: #EEEEEE;    
    }
    header a:hover {
    color: #EEEEEE;
    }
    header a:visited {
    color: #EEEEEE;
    }
    header a:active {
    color: #EEEEEE;
    }
    footer {
    padding-top: 10px;
    padding-bottom: 10px;
    background-color: #333333;
    color: #BBBBBB;
    }
    table {
    width: 100%;
    table-layout: fixed;
    }
    th {
    text-align: center;
    vertical-align: middle;
    }
    td {
    text-align: center;
    vertical-align: middle;
    }
    th#strong{
    color: #FF33CC;
    }
    #pinkstrong{
    color: #FF33CC;
    }
    audio {
    width: 100%;
    }
    .jumbotroncolor {
    background-color: #333333;
    color: #EEEEEE;
    }
    .thumbnailsize {
    width: 200px;
    }
    .thumbnailshadow {
    filter: drop-shadow(5px 5px 5px #aaa);
    }
    @media screen and (max-width:767px) {
    h1 { font-size:20pt;}
    }
    @media screen and (min-width:768px){
    h1 { font-size:30pt;}
    }
  </style>

  <body>

    <header class="header" id="top">
      <div class="jumbotron jumbotroncolor text-center">
	<div class="container">
	  <h2><p style="text-align:center">Soft-threshold Attention based Audio-visual Speech Enhancement Network</p></h2>
	  
	  <p class="lead">
		<p style="text-align:center">
	    <a>Xinmeng Xu</a>&nbsp;&nbsp;&nbsp;
		<a>Dejun Li</a>&nbsp;&nbsp;&nbsp;
	    <a>Jianjun Hao</a>&nbsp;&nbsp;&nbsp;
		</p>
		<p style="text-align:center">
		Trinity College Dublin, Ireland<br>
		Hubei University of Chinese Medcine, P.R. China
		</p>
	  </p>
	  <p class="lead">
	    <p style="text-align:center">Submitted to ICASSP 2022</p><br>
	  </p>
	</div>
      </div>
    </header>

    <main>            
      <div class="container">
	<hr>
	
	<div class="row" id="introduction">
	  <div class="col-md-12">
	    <h2>Soft-threshold Attention based Audio-visual Speech Enhancement Network</h2>
	    <p>
		    Audio-visual speech enhancement system is regarded to beone of promising solutions for isolating and enhancing speech 
		    of desired speaker. Conventional methods focus on predictingclean speech spectrum via a naive convolution neural network based
		    encoder-decoder architecture, and these methods a) arenot adequate to use data fully and effectively, b) cannot pro-cess features
		    selectively.  To tackle these problems, this pa-per proposes a soft-threshold attention based convolution re-current network for
		    audio-visual speech enhancement, whicha) apply a novel audio-visual fusion strategy that fuses audioand visual features layer by 
		    layer in encoding stage, and thatfeeds fused audio-visual features to each corresponding de-coder layer, and more importantly, b)
		    which introduces a soft-threshold attention applied on every decoder layers to selectthe informative modality softly.   
		    Experimental results illus-trate that the proposed architecture obtains consistently bet-ter performance than recent models
		    of both PESQ and STOIscores.
	    </p>

	    <figure class="figure">				
		<center>
		  <a name="fig1"><img src="image1/yui.png" class="figure-img" width="80%" alt="network"></a>	
		</center>
	      </figure>
	  </div>
	</div>

	<hr>
	
	<div class="row" id="results">
	  <div class="col-md-12">
	    <h3>Dataset</h3>
	    <ul>
		  <li>We used <a href="http://sigmedia.tcd.ie/TCDTIMIT">the TCD-TIMIT dataset</a> and <a href="http://spandh.dcs.shef.ac.uk/avlombard/"> GRID Corpus dataset</a>.</li> 
		


	    </ul>
	    
	    
	    <hr>
		<h4><a name="exp1">Experiment Results</a></h4>
	    
	    <p class="lead"> Male speech + ambient noise</p>
	    <div>
	      <table class="table">
		<thead>
		  <tr>
		    <th></th>
		    <th>Noisy</th>
		    <th>Enhanced-AVCRN</a></th>
			<th>Enhanced-AVCRN + STA</th>
		  </tr>
		</thead>
		<tbody>
		  <tr>
		    <th scope="row">Sample</th>
		    <td>
		      <video controls>
			<source src="video1/n_m_m.mp4" type="video/mp4" />
		      </video>
		    </td>
		    <td>
		      <video controls>
			<source src="video1/n_m_mf.mp4" type="video/mp4" />
		      </video>
		    </td>
		    <td>
		      <video controls>
			<source src="video1/n_m_am.mp4" type="video/mp4" />
		      </video>
		    </td>
		  </tr>
		</tbody>
	      </table>
	    </div>

	    <p class="lead"> Female speech + ambient noise</p>
	    <div>
	      <table class="table">
		<thead>
		  <tr>
		    <th></th>
		    <th>Noisy</th>
		    <th>Enhanced-AVCRN</a></th>
			<th>Enhanced-AVCRN + STA</th>
		  </tr>
		</thead>
		<tbody>
		  <tr>
		    <th scope="row">Sample</th>
		    <td>
		      <video controls>
			<source src="video1/n_f_m.mp4" type="video/mp4" />
		      </video>
		    </td>
		    <td>
		      <video controls>
			<source src="video1/n_f_mf.mp4" type="video/mp4" />
		      </video>
		    </td>
		    <td>
		      <video controls>
			<source src="video1/n_f_am.mp4" type="video/mp4" />
		      </video>
		    </td>
		  </tr>
		</tbody>
	      </table>
	    </div>

	    <p class="lead">Female speech + unknown talker speech</p>
	    <div>
	      <table class="table">
		<thead>
		  <tr>
		    <th></th>
		    <th>Mixture</th>
		    <th>Enhanced-AVCRN</a></th>
			<th>Enhanced-AVCRN+STA</th>
		  </tr>
		</thead>
		<tbody>
		  <tr>
		    <th scope="row">Sample</th>
		    <td>
		      <video controls>
			<source src="video1/s_f_m.mp4" type="video/mp4" />
		      </video>
		    </td>
			<td>
		      <video controls>
			<source src="video1/s_f_mf.mp4" type="video/mp4" />
		      </video>
		    </td>
		    <td>
		      <video controls>
			<source src="video1/s_f_am.mp4" type="video/mp4" />
		      </video>
		    </td>
		  </tr>
		</tbody>
	      </table>
	    </div>

		 
	    <p class="lead">Male speech + unknown talker speech</p>
	   <div>
	      <table class="table">
		<thead>
		  <tr>
		    <th></th>
		    <th>Mixture</th>
			<th>Enhanced-AVCRN</a></th>
		    <th>Enhanced-AVCRN + STA</th>
		  </tr>
		</thead>
		<tbody>
		  <tr>
		    <th scope="row">Sample</th>
		    <td>
		      <video controls>
			<source src="video1/s_m_m.mp4" type="video/mp4" />
		      </video>
		    </td>
			<td>
		      <video controls>
			<source src="video1/s_m_mf.mp4" type="video/mp4" />
		      </video>
		    </td>
		    <td>
		      <video controls>
			<source src="video1/s_m_am.mp4" type="video/mp4" />
		      </video>
		    </td>
		  </tr>
		</tbody>
	      </table>
	    </div>
		<hr>
	  </div>
	</div>
	<hr>
	
	


	<hr>
	<strong>NOTE:</strong>
	<ul>
		<li>If you want to cite this paper, try this:
			Xinmeng Xu, Dejun Li, Jianjun Hao,  "Soft-threshold Attention based Audio-visual Speech Enhancement Network"</li>
	</ul>
      </div>
    </main>
    <script src="../../js/bootstrap.min.js"></script>
  </body>
</html>
